import pandas as pd
import logging
import numpy as np
import sys
import matplotlib.pyplot as plt
from sklearn.cross_validation import train_test_split

### Assignment Owner: Hao Xu
### Edited By: Kshitiz Sethia

#######################################
####Q2.1: Normalization

def feature_normalization(train, test):
    """Rescale the data so that each feature in the training set is in
    the interval [0,1], and apply the same transformations to the test
    set, using the statistics computed on the training set.
    
    Args:
        train - training set, a 2D numpy array of size (num_instances, num_features)
        test  - test set, a 2D numpy array of size (num_instances, num_features)
    Returns:
        train_normalized - training set after normalization
        test_normalized  - test set after normalization

    """
    mins_of_features = np.amin(train, axis=0)
    maxs_of_features = np.amax(train, axis=0)
    range_of_features = maxs_of_features-mins_of_features
    range_of_features[range_of_features==0] = 1
    
    train_normalized = (train - mins_of_features)/range_of_features
    test_normalized = (test - mins_of_features)/range_of_features
    
    return (train_normalized, test_normalized)

    
########################################
####Q2.2a: The square loss function

def compute_square_loss(X, y, theta):
    """
    Given a set of X, y, theta, compute the square loss for predicting y with X*theta
    
    Args:
        X - the feature vector, 2D numpy array of size (num_instances, num_features)
        y - the label vector, 1D numpy array of size (num_instances)
        theta - the parameter vector, 1D array of size (num_features)
    
    Returns:
        loss - the square loss, scalar
    """
    """"X = np.asmatrix(X)
    y = np.matrix.transpose(np.asmatrix(y))
    theta = np.matrix.transpose(np.asmatrix(theta))
    """
    term = (np.dot(X,theta) - y)
    #loss = (term.transpose())* term
    loss = term.dot(term)
    return loss/(2*y.size)


########################################
###Q2.2b: compute the gradient of square loss function
def compute_square_loss_gradient(X, y, theta):
    """
    Compute gradient of the square loss (as defined in compute_square_loss), at the point theta.
    
    Args:
        X - the feature vector, 2D numpy array of size (num_instances, num_features)
        y - the label vector, 1D numpy array of size (num_instances)
        theta - the parameter vector, 1D numpy array of size (num_features)
    
    Returns:
        grad - gradient vector, 1D numpy array of size (num_features)
    """
    """X = np.asmatrix(X)
    y = np.matrix.transpose(np.asmatrix(y))
    theta = np.matrix.transpose(np.asmatrix(theta))
    grad = ((X*theta - y).transpose())*X
    """
    """print "X: " +str(X.shape)
    print "y: " +str(y.shape)
    print "theta: " +str(theta.shape)
    """
    temp = np.dot(X, theta)
    temp = np.transpose(temp - y)
    grad = np.dot(temp, X)
    #return np.asarray(grad/y.size)   
    return grad/y.size
        
###########################################
###Q2.3a: Gradient Checker
#Getting the gradient calculation correct is often the trickiest part
#of any gradient-based optimization algorithm.  Fortunately, it's very
#easy to check that the gradient calculation is correct using the
#definition of gradient.
#See http://ufldl.stanford.edu/wiki/index.php/Gradient_checking_and_advanced_optimization
def grad_checker(X, y, theta, epsilon=0.01, tolerance=1e-4): 
    """Implement Gradient Checker
    Check that the function compute_square_loss_gradient returns the
    correct gradient for the given X, y, and theta.

    Let d be the number of features. Here we numerically estimate the
    gradient by approximating the directional derivative in each of
    the d coordinate directions: 
    (e_1 = (1,0,0,...,0), e_2 = (0,1,0,...,0), ..., e_d = (0,...,0,1) 

    The approximation for the directional derivative of J at the point
    theta in the direction e_i is given by: 
    ( J(theta + epsilon * e_i) - J(theta - epsilon * e_i) ) / (2*epsilon).

    We then look at the Euclidean distance between the gradient
    computed using this approximation and the gradient computed by
    compute_square_loss_gradient(X, y, theta).  If the Euclidean
    distance exceeds tolerance, we say the gradient is incorrect.

    Args:
        X - the feature vector, 2D numpy array of size (num_instances, num_features)
        y - the label vector, 1D numpy array of size (num_instances)
        theta - the parameter vector, 1D numpy array of size (num_features)
        epsilon - the epsilon used in approximation
        tolerance - the tolerance error
    
    Return:
        A boolean value indicate whether the gradient is correct or not

    """
    true_gradient = compute_square_loss_gradient(X, y, theta) #the true gradient
    num_features = theta.shape[0]
    approx_grad = np.zeros(num_features)
    for index in range(num_features):
        step = np.zeros(num_features)
        step[index] = epsilon
        approx_grad[index] = (compute_square_loss(X, y, theta+step)-compute_square_loss(X, y, theta-step))/(2*epsilon)

    if(np.linalg.norm(true_gradient-approx_grad)>tolerance):
        return False
    else:
        return True
#################################################
###Q2.3b: Generic Gradient Checker
def generic_gradient_checker(X, y, theta, objective_func, gradient_func, epsilon=0.01, tolerance=1e-4):
    """
    The functions takes objective_func and gradient_func as parameters. And check whether gradient_func(X, y, theta) returned
    the true gradient for objective_func(X, y, theta).
    Eg: In LSR, the objective_func = compute_square_loss, and gradient_func = compute_square_loss_gradient
    """
    true_gradient = gradient_func(X, y, theta) #the true gradient
    num_features = theta.shape[0]
    approx_grad = np.zeros(num_features)
    for index in range(num_features):
        step = np.zeros(num_features)
        step[index] = epsilon
        approx_grad[index] = (objective_func(X, y, theta+step)-objective_func(X, y, theta-step))/(2*epsilon)

    if(np.linalg.norm(true_gradient-approx_grad)>tolerance):
        return False
    else:
        return True

def generic_regularized_gradient_checker(X, y, theta, lambda_reg, objective_func, gradient_func, epsilon=0.01, tolerance=1e-4):
    """
    The functions takes objective_func and gradient_func as parameters. And check whether gradient_func(X, y, theta) returned
    the true gradient for objective_func(X, y, theta).
    Eg: In LSR, the objective_func = compute_square_loss, and gradient_func = compute_square_loss_gradient
    """
    true_gradient = gradient_func(X, y, theta, lambda_reg) #the true gradient
    num_features = theta.shape[0]
    approx_grad = np.zeros(num_features)
    for index in range(num_features):
        step = np.zeros(num_features)
        step[index] = epsilon
        approx_grad[index] = (objective_func(X, y, theta+step, lambda_reg)\
                              -objective_func(X, y, theta-step, lambda_reg))/(2*epsilon)
    
    if(np.linalg.norm(true_gradient-approx_grad)>tolerance):
        return False
    else:
        return True

####################################
####Q2.4a: Batch Gradient Descent
def batch_grad_descent(X, y, alpha=0.1, num_iter=1000, grad_checker=False):
    """
    In this question you will implement batch gradient descent to
    minimize the square loss objective
    
    Args:
        X - the feature vector, 2D numpy array of size (num_instances, num_features)
        y - the label vector, 1D numpy array of size (num_instances)
        alpha - step size in gradient descent
        num_iter - number of iterations to run 
        grad_checker - a boolean value indicating whether checking the gradient when updating
        
    Returns:
        theta_hist - store the the history of parameter vector in iteration, 2D numpy array of size (num_iter+1, num_features) 
                    for instance, theta in iteration 0 should be theta_hist[0], theta in ieration (num_iter) is theta_hist[-1]
        loss_hist - the history of objective function vector, 1D numpy array of size (num_iter+1) 
    """
    num_instances, num_features = X.shape[0], X.shape[1]
    theta_hist = np.zeros((num_iter+1, num_features))  #Initialize theta_hist
    loss_hist = np.zeros(num_iter+1) #initialize loss_hist
    theta = np.ones(num_features) #initialize theta
    
    theta_hist[0] = theta
    
    if(grad_checker):
        iteration=0
        while(True):
            if(generic_gradient_checker(X, y, theta, compute_square_loss, compute_square_loss_gradient)):
                #above line introduces inefficiency as it is already computes
                #loss and gradient for theta, which is again computed below
                theta = theta - alpha*compute_square_loss_gradient(X, y, theta)   
                theta_hist[iteration] = theta
                loss_hist[iteration] = compute_square_loss(X, y, theta)
                iteration+=1
                if(iteration>=num_iter):
                    break
            else:
                raise("Gradient checking failed!")
        loss_hist[iteration] = compute_square_loss(X, y, theta)
        
    else:
        iteration=0
        while(True):
            theta = theta - alpha*compute_square_loss_gradient(X, y, theta)   
            theta_hist[iteration] = theta
            loss_hist[iteration] = compute_square_loss(X, y, theta)
            iteration+=1
            if(iteration>=num_iter):
                break
        loss_hist[iteration] = compute_square_loss(X, y, theta)
    
    return (theta_hist, loss_hist)


####################################
###Q2.4b: Implement backtracking line search in batch_gradient_descent
###Check http://en.wikipedia.org/wiki/Backtracking_line_search for details
#TODO
    


###################################################
###Q2.5a: Compute the gradient of Regularized Batch Gradient Descent
def compute_regularized_square_loss_gradient(X, y, theta, lambda_reg):
    """
    Compute the gradient of L2-regularized square loss function given X, y and theta
    
    Args:
        X - the feature vector, 2D numpy array of size (num_instances, num_features)
        y - the label vector, 1D numpy array of size (num_instances)
        theta - the parameter vector, 1D numpy array of size (num_features)
        lambda_reg - the regularization coefficient
    
    Returns:
        grad - gradient vector, 1D numpy array of size (num_features)
    """
    grad = compute_square_loss_gradient(X, y, theta)+2*lambda_reg*theta
    return grad

def compute_regularized_square_loss(X, y, theta, lambda_reg):
    """
    Given a set of X, y, theta, compute the square loss for predicting y with X*theta
    
    Args:
        X - the feature vector, 2D numpy array of size (num_instances, num_features)
        y - the label vector, 1D numpy array of size (num_instances)
        theta - the parameter vector, 1D array of size (num_features)
        lambda_reg - the regularization coefficient
    
    Returns:
        loss - the square loss, scalar
    """
    """print "X: " +str(X.shape)
    print "y: " +str(y.shape)
    print "theta: " +str(theta.shape)
    #hack
    if(theta.shape[1]>1):
        theta = theta[0,:]
    print "theta: " +str(theta.shape)
    """
    loss = compute_square_loss(X, y, theta) + lambda_reg*theta.dot(theta)
    return loss


###################################################
###Q2.5b: Batch Gradient Descent with regularization term
def regularized_grad_descent(X, y, alpha=0.1, lambda_reg=1, num_iter=1000, grad_checker=False):
    """
    Args:
        X - the feature vector, 2D numpy array of size (num_instances, num_features)
        y - the label vector, 1D numpy array of size (num_instances)
        alpha - step size in gradient descent
        lambda_reg - the regularization coefficient
        numIter - number of iterations to run 
        
    Returns:
        theta_hist - the history of parameter vector, 2D numpy array of size (num_iter+1, num_features) 
        loss_hist - the history of regularized loss value, 1D numpy array
    """
    
    (num_instances, num_features) = X.shape
    theta = np.ones(num_features) #Initialize theta
    theta_hist = np.zeros((num_iter+1, num_features))  #Initialize theta_hist
    loss_hist = np.zeros(num_iter+1) #Initialize loss_hist
    theta_hist[0] = theta
    
    if(grad_checker):
        iteration=0
        while(True):
            if(generic_regularized_gradient_checker(X, y, theta, lambda_reg, compute_regularized_square_loss, compute_regularized_square_loss_gradient)):
                #above line introduces inefficiency as it is already computes
                #loss and gradient for theta, which is again computed below
                #print "with_checking_iteration: " +str(iteration)
                loss_hist[iteration] = compute_regularized_square_loss(X, y, theta, lambda_reg)
                theta = theta - alpha*compute_regularized_square_loss_gradient(X, y, theta, lambda_reg)   
                theta_hist[iteration] = theta
                iteration+=1
                if(iteration>=num_iter):
                    break
            else:
                raise("Gradient checking failed!")
        loss_hist[iteration] = compute_regularized_square_loss(X, y, theta, lambda_reg)
        
    else:
        iteration=0
        while(True):
            #print "no_checking_iteration: " +str(iteration)
            
            loss_hist[iteration] = compute_regularized_square_loss(X, y, theta, lambda_reg)
            theta = theta - alpha*compute_regularized_square_loss_gradient(X, y, theta, lambda_reg)   
            theta_hist[iteration] = theta
            iteration+=1
            if(iteration>=num_iter):
                break
        loss_hist[iteration] = compute_regularized_square_loss(X, y, theta, lambda_reg)
        
    return (theta_hist, loss_hist)

#############################################
##Q2.5c: Visualization of Regularized Batch Gradient Descent
##X-axis: log(lambda_reg)
##Y-axis: square_loss
def plot_these(X_train, y_train, X_test, y_test, alpha=0.1, num_iter=1000):
    
    lambdas = np.array([0.01, 0.1, 1, 10, 100])
    alphas = np.array([0.1,0.1, 0.01, 0.01, 0.001])
    training_losses = np.zeros(len(lambdas))
    test_losses = np.zeros(len(lambdas))
    
    for index in range(len(lambdas)):
        #print "regularized gradient descent for lambda: " +str(lambdas[index])
        theta_hist, loss_hist = regularized_grad_descent(X_train, y_train, alphas[index], lambdas[index], num_iter, True)
        training_losses[index] = loss_hist[-1]
        test_losses[index] = compute_regularized_square_loss(X_test, y_test, theta_hist[-1], lambdas[index])
    
    figure = plt.figure()
    
    rect = 0.1,0.1,0.8,0.8
    axes = figure.add_axes(rect)
    axes.plot(np.log(lambdas), training_losses, 'r')
    axes.plot(np.log(lambdas), test_losses, 'g')
    
    axes.set_xlabel("log lambda")
    axes.set_ylabel("losses")
    
    plt.show()

#############################################
###Q2.6a: Stochastic Gradient Descent
def stochastic_grad_descent(X, y, alpha=0.1, lambda_reg=1, num_iter=1000):
    """
    In this question you will implement stochastic gradient descent with a regularization term
    
    Args:
        X - the feature vector, 2D numpy array of size (num_instances, num_features)
        y - the label vector, 1D numpy array of size (num_instances)
        alpha - string or float. step size in gradient descent
                NOTE: In SGD, it's not always a good idea to use a fixed step size. Usually it's set to 1/sqrt(t) or 1/t
                if alpha is a float, then the step size in every iteration is alpha.
                if alpha == "1/sqrt(t)", alpha = 1/sqrt(t)
                if alpha == "1/t", alpha = 1/t
        lambda_reg - the regularization coefficient
        num_iter - number of epochs (i.e number of times) to go through the whole training set
    
    Returns:
        theta_hist - the history of parameter vector, 3D numpy array of size (num_iter, num_instances, num_features) 
        loss hist - the history of regularized loss function vector, 2D numpy array of size(num_iter, num_instances)
    """
    num_instances, num_features = X.shape[0], X.shape[1]
    theta = np.ones(num_features) #Initialize theta
    
    
    theta_hist = np.zeros((num_iter, num_instances, num_features))  #Initialize theta_hist
    loss_hist = np.zeros((num_iter, num_instances)) #Initialize loss_hist
    
    theta_hist[0,0,:] = theta
    for epoch in range(num_iter):
        for instance in range(num_instances):
            theta = theta - alpha*compute_square_loss_gradient(X[instance], y[instance], theta)
            theta_hist[epoch, instance, :] = theta
            loss_hist[epoch, instance] = compute_regularized_square_loss(X[instance], y[instance], theta, lambda_reg)
            
    loss_hist[-1,-1] = compute_square_loss(X[num_instances-1], y[num_instances-1], theta, lambda_reg)
    
    
################################################
###Q2.6b Visualization that compares the convergence speed of batch
###and stochastic gradient descent for various approaches to step_size
##X-axis: Step number (for gradient descent) or Epoch (for SGD)
##Y-axis: log(objective_function_value)

def main():
    #Loading the dataset
    print('loading the dataset')
    
    df = pd.read_csv('hw1-data.csv', delimiter=',')
    X = df.values[:,:-1]
    y = df.values[:,-1]

    print('Split into Train and Test')
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size =100, random_state=10)

    print("Scaling all to [0, 1]")
    X_train, X_test = feature_normalization(X_train, X_test)
    X_train = np.hstack((X_train, np.ones((X_train.shape[0], 1)))) #Add bias term
    X_test = np.hstack((X_test, np.ones((X_test.shape[0], 1)))) #Add bias term

    #do your thing here
    #plot_these(X_train, y_train, X_test, y_test, 0.1, 1000)
    alpha = 0.001
    iterations = 1000
    lambda_reg = 10000
    theta_hist, loss_hist = regularized_grad_descent(X_train, y_train, alpha, lambda_reg, iterations, False)
    test_loss = compute_regularized_square_loss(X_test, y_test, theta_hist[-1], lambda_reg)
    #theta_hist, loss_hist = batch_grad_descent(X_train, y_train, alpha, iterations, True)
    #test_loss = compute_square_loss(X_test, y_test, theta_hist[-1])
    #print loss_hist
    figure = plt.figure()
    rect = 0.1,0.1,0.8,0.8
    axes = figure.add_axes(rect)
    axes.plot(np.arange(iterations+1), loss_hist, 'r')
    axes.set_xlabel("iteration")
    axes.set_ylabel("losses")
    title="regularized_gradient_descent for step=" +str(alpha)\
            +", iter=" +str(iterations)\
            +" and lambda=" +str(lambda_reg)\
            +" | test loss = " +str(test_loss)
    """
    title="batch_gradient_descent for step=" +str(alpha)\
            +" and iter=" +str(iterations)\
            +" | test loss = " +str(test_loss)
    """
    axes.set_title(title)
    
    plt.show()


if __name__ == "__main__":
    main()
